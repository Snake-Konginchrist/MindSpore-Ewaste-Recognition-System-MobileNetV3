# 技术架构详解

## MobileNetV3 网络结构

MobileNetV3 是 Google 提出的移动端神经网络架构，本项目使用其 Small 版本，具有以下特点：

### 创新点

- 结合 NAS（神经架构搜索）和 NetAdapt 算法
- 引入 Hard Swish 激活函数
- 改进的 SE（Squeeze-and-Excitation）模块
- 优化的网络结构

### 核心模块

#### 倒置残差块 (Inverted Residual Block)
```
输入 → 1x1 PW扩展 → DW卷积 → SE模块 → 1x1 PW压缩 → 输出
```

#### SE 注意力模块
```
特征图 → 全局平均池化 → 1x1 Conv降维 → ReLU → 1x1 Conv升维 → Hard Sigmoid → 特征重标定
```

#### Hard Swish 激活函数
```
H-Swish(x) = x * ReLU6(x + 3) / 6
```

### 网络架构详细参数

| 层 | 输入大小 | 算子 | 扩展因子 | 输出通道 | SE | HS | 步长 |
|---|---------|------|----------|----------|----|----|-----|
| 0 | 224×224 | Conv2d 3×3 | - | 16 | - | √ | 2 |
| 1 | 112×112 | bneck 3×3 | 1 | 16 | √ | - | 2 |
| 2 | 56×56 | bneck 3×3 | 4.5 | 24 | - | - | 2 |
| 3 | 28×28 | bneck 3×3 | 3.67 | 24 | - | - | 1 |
| 4 | 28×28 | bneck 5×5 | 4 | 40 | √ | √ | 2 |
| 5 | 14×14 | bneck 5×5 | 6 | 40 | √ | √ | 1 |
| 6 | 14×14 | bneck 5×5 | 6 | 40 | √ | √ | 1 |
| 7 | 14×14 | bneck 5×5 | 3 | 48 | √ | √ | 1 |
| 8 | 14×14 | bneck 5×5 | 3 | 48 | √ | √ | 1 |
| 9 | 14×14 | bneck 5×5 | 6 | 96 | √ | √ | 2 |
| 10 | 7×7 | bneck 5×5 | 6 | 96 | √ | √ | 1 |
| 11 | 7×7 | bneck 5×5 | 6 | 96 | √ | √ | 1 |

## 模型特点

### 轻量级设计
- 采用深度可分离卷积
- 使用 1x1 卷积进行通道数调整
- 模型参数量小，适合移动端部署

### 优化的激活函数
- 使用 Hard Swish 替代 ReLU
- 降低计算量，提高性能

### 注意力机制
- 集成 SE 模块
- 自适应特征重标定
- 提高特征表达能力

### 训练优化
- 使用余弦退火学习率调度
- 批归一化层用于稳定训练
- 数据增强提高模型鲁棒性

## 训练策略

### 优化器
- Momentum 优化器
- Nesterov 加速梯度
- 权重衰减防止过拟合

### 学习率策略
- 余弦退火调度
- 初始学习率：0.001
- 动态调整

### 训练参数
- 批次大小：32
- 训练轮数：100（支持早停）
- 使用模型检查点保存最佳模型

## 数据预处理

### 图像变换
- 调整图像大小至 224×224
- 随机裁剪和水平翻转
- 标准化处理

### 数据增强
- 随机裁剪
- 随机水平翻转
- 标准化（均值和标准差）

## 并行处理优化

### 并行训练
- 利用多核 CPU 加速模型训练
- 用户可以指定使用的 CPU 核心数（默认使用全部核心）
- 自动设置最佳线程数和工作进程数

### 并行数据处理
- 多线程数据加载和预处理
- 提高数据吞吐量，减少训练等待时间
- 支持数据预取和缓存

### 混合精度训练
- 自动混合精度（AMP）支持
- 在保持精度的同时提高训练速度
- 减少内存占用

### 优化器增强
- 并行优化器支持
- Nesterov加速梯度
- 自适应学习率调度 